{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53136015",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q --upgrade openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "def9f3cb-4836-4702-ba09-7553fd086a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in /opt/anaconda3/lib/python3.13/site-packages (5.45.0)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (4.7.0)\n",
      "Requirement already satisfied: audioop-lts<1.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (0.2.2)\n",
      "Requirement already satisfied: brotli>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (1.1.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (0.116.1)\n",
      "Requirement already satisfied: ffmpy in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (0.6.1)\n",
      "Requirement already satisfied: gradio-client==1.13.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (1.13.0)\n",
      "Requirement already satisfied: groovy~=0.1 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (0.34.4)\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: orjson~=3.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (3.11.3)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (11.1.0)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (2.10.3)\n",
      "Requirement already satisfied: pydub in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (0.13.0)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (0.47.3)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (0.17.4)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (0.35.0)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.13/site-packages (from gradio-client==1.13.0->gradio) (2025.3.2)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio-client==1.13.0->gradio) (15.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.13/site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.13/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.17.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.10)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<2.12,>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<2.12,>=2.0->gradio) (2.27.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from typer<1.0,>=0.12->gradio) (1.5.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/lib/python3.13/site-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.3.0)\n"
     ]
    }
   ],
   "source": [
    "# Install gradio\n",
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "109350ef-406d-4e98-9bc9-5d24f125061f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI client successfully configured.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from IPython.display import display, Markdown\n",
    "from openai import OpenAI\n",
    "\n",
    "# This will be used to load the API key from the .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Get the OpenAI API keys from environment variables\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Let's configure the OpenAI Client using our key\n",
    "openai_client = OpenAI(api_key = openai_api_key)\n",
    "print(\"OpenAI client successfully configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c212106e-3834-4446-966a-d2596cecac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function to display markdown nicely\n",
    "def print_markdown(text):\n",
    "    \"\"\"Displays text as Markdown in Jupyter.\"\"\"\n",
    "    display(Markdown(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "019dfbde-f2cb-4d45-81ab-77e7b662069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ai_tutor_response(user_question):\n",
    "    \"\"\"\n",
    "    Sends a question to the OpenAI API, asking it to respond as an AI Tutor.\n",
    "\n",
    "    Args:\n",
    "        user_question (str): The question asked by the user.\n",
    "\n",
    "    Returns:\n",
    "        str: The AI's response, or an error message.\n",
    "    \"\"\"\n",
    "    # Define the system prompt - instructions for the AI's personality and role\n",
    "    system_prompt = \"You are a helpful and patient AI Tutor. Explain concepts clearly and concisely.\"\n",
    "\n",
    "    try:\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model = \"gpt-4o-mini\",\n",
    "            messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_question}],\n",
    "            temperature = 0.7,  # Allows for some creativity but keeps responses focused\n",
    "        )\n",
    "        # Extract the answer content\n",
    "        ai_response = response.choices[0].message.content\n",
    "        return ai_response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return f\"Sorry, I encountered an error trying to get an answer: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc754a24-c7fc-4e23-a35f-a6d6b78443fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Asking the AI Tutor: 'Could you explain the concept of functions in Python and their purpose in programming?'"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "ðŸ¤– AI Tutor's Response:\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Certainly! Functions in Python are a fundamental concept that helps in organizing and structuring code effectively. Here's a clear breakdown of what functions are and their purpose in programming:\n",
       "\n",
       "### What is a Function?\n",
       "\n",
       "A function is a reusable block of code that performs a specific task. It can take inputs, process them, and return an output. Functions help to avoid repetition in code, making it cleaner and easier to maintain.\n",
       "\n",
       "### Key Components of a Function\n",
       "\n",
       "1. **Definition**: A function is defined using the `def` keyword, followed by the function name and parentheses. Inside the parentheses, you can specify parameters (inputs).\n",
       "   ```python\n",
       "   def function_name(parameters):\n",
       "       # Code block\n",
       "       return result\n",
       "   ```\n",
       "\n",
       "2. **Parameters**: These are variables that allow you to pass data into the function. They are optional, and a function can have none, one, or multiple parameters.\n",
       "\n",
       "3. **Return Value**: A function can return a value using the `return` statement. If no return statement is present, the function returns `None` by default.\n",
       "\n",
       "4. **Calling a Function**: To execute the code inside a function, you call it by its name and provide the necessary arguments (if any).\n",
       "   ```python\n",
       "   function_name(arguments)\n",
       "   ```\n",
       "\n",
       "### Example of a Function\n",
       "\n",
       "Hereâ€™s a simple example of a function that adds two numbers:\n",
       "\n",
       "```python\n",
       "def add_numbers(a, b):\n",
       "    result = a + b\n",
       "    return result\n",
       "\n",
       "# Calling the function\n",
       "sum_result = add_numbers(3, 5)\n",
       "print(sum_result)  # Output: 8\n",
       "```\n",
       "\n",
       "### Purpose of Functions in Programming\n",
       "\n",
       "1. **Modularity**: Functions break down complex problems into smaller, manageable pieces. Each function can focus on a specific task.\n",
       "\n",
       "2. **Reusability**: Once a function is defined, it can be called multiple times throughout the program, reducing code duplication.\n",
       "\n",
       "3. **Readability**: Functions can make code more understandable. Good function names can describe what the function does, making it easier for others (and yourself) to read and maintain the code later.\n",
       "\n",
       "4. **Abstraction**: Functions allow you to hide complex operations behind a simple interface. Users of the function donâ€™t need to know the details of how it works; they just need to know how to use it.\n",
       "\n",
       "5. **Testing and Debugging**: Functions can be tested individually, making it easier to identify issues and ensuring that each part of your program works correctly.\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "In summary, functions are essential tools in Python programming (and programming in general) that promote organization, reusability, and clarity in your code. Understanding how to define, call, and use functions will significantly enhance your coding skills."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First sample question\n",
    "test_question = \"Could you explain the concept of functions in Python and their purpose in programming?\"\n",
    "print_markdown(f\"Asking the AI Tutor: '{test_question}'\")\n",
    "\n",
    "# Call the function and store the response\n",
    "tutor_answer = get_ai_tutor_response(test_question)\n",
    "\n",
    "# Print the AI's response\n",
    "print_markdown(\"\\nðŸ¤– AI Tutor's Response:\\n\")\n",
    "print_markdown(tutor_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6143675f-2002-4278-9980-8a94f1104e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Asking the AI Tutor: 'Explain the concept of gravity'"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "ðŸ¤– AI Tutor's Response:\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Gravity is a fundamental force of nature that attracts two objects with mass towards each other. It is responsible for keeping planets in orbit around stars, moons around planets, and for the falling of objects to the ground. \n",
       "\n",
       "Here are some key points about gravity:\n",
       "\n",
       "1. **Newton's Law of Universal Gravitation**: Sir Isaac Newton formulated the law of universal gravitation in the 17th century. It states that every mass attracts every other mass with a force that is directly proportional to the product of their masses and inversely proportional to the square of the distance between their centers. This means that the greater the mass of an object, the stronger its gravitational pull, and the farther apart two objects are, the weaker their gravitational attraction.\n",
       "\n",
       "2. **Einstein's Theory of General Relativity**: In the early 20th century, Albert Einstein proposed a new understanding of gravity through his theory of general relativity. He described gravity not as a force but as a curvature of space-time caused by mass. According to this theory, massive objects like planets and stars warp the fabric of space-time around them, and this curvature affects the motion of other objects.\n",
       "\n",
       "3. **Effects of Gravity**: Gravity influences many aspects of our daily lives, from keeping our feet on the ground to governing the motion of celestial bodies. It plays a critical role in the formation of galaxies, stars, and planets, as well as phenomena like tides and black holes.\n",
       "\n",
       "4. **Gravitational Field**: The gravitational effect of an object can be described in terms of a gravitational field, which is a region around the object where other masses experience a force. The strength of this field decreases with distance from the object.\n",
       "\n",
       "In summary, gravity is a fundamental interaction that governs the motion and behavior of objects in the universe, whether they are as small as an apple falling from a tree or as large as galaxies colliding in space."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Secondsample question\n",
    "test_question = \"Explain the concept of gravity\"\n",
    "print_markdown(f\"Asking the AI Tutor: '{test_question}'\")\n",
    "tutor_answer = get_ai_tutor_response(test_question)\n",
    "print_markdown(\"\\nðŸ¤– AI Tutor's Response:\\n\")\n",
    "print_markdown(tutor_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9d39340-0e79-4732-aacc-12d0822c817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Gradio\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1405320d-a3b8-4372-ba81-c5ad0efc496e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/gradio/interface.py:418: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Gradio Interface...\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Gradio interface\n",
    "# fn: The function to wrap (our AI tutor function)\n",
    "# inputs: A component for the user to type their question\n",
    "# outputs: A component to display the AI's answer\n",
    "# title/description: Text for the UI heading\n",
    "ai_tutor_interface_simple = gr.Interface(\n",
    "    fn = get_ai_tutor_response,\n",
    "    inputs = gr.Textbox(lines = 2, placeholder = \"Ask the AI Tutor anything...\", label = \"Your Question\"),\n",
    "    outputs = gr.Textbox(label = \"AI Tutor's Answer\"),\n",
    "    title = \"ðŸ¤– Simple AI Tutor\",\n",
    "    description = \"Enter your question below and the AI Tutor will provide an explanation. Powered by OpenAI.\",\n",
    "    allow_flagging = \"never\",  # Disables the flagging feature for simplicity\n",
    ")\n",
    "\n",
    "print(\"Launching Gradio Interface...\")\n",
    "ai_tutor_interface_simple.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6c5ce2-9b49-4f7b-882b-aed34cb87d26",
   "metadata": {},
   "source": [
    "## ADD STREAMING FOR AN ENHANCED CHAT EXPERIENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f76c3630-580e-4daf-8fc8-bb48f8057104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream_ai_tutor_response supports streaming\n",
    "def stream_ai_tutor_response(user_question):\n",
    "    \"\"\"\n",
    "    Sends a question to the OpenAI API and streams the response as a generator.\n",
    "\n",
    "    Args:\n",
    "        user_question (str): The question asked by the user.\n",
    "\n",
    "    Yields:\n",
    "        str: Chunks of the AI's response.\n",
    "    \"\"\"\n",
    "\n",
    "    system_prompt = \"You are a helpful and patient AI Tutor. Explain concepts clearly and concisely.\"\n",
    "\n",
    "    try:\n",
    "        stream = openai_client.chat.completions.create(\n",
    "            model = \"gpt-4o-mini\",\n",
    "            messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_question}],\n",
    "            temperature = 0.7,\n",
    "            stream = True,  # Enable streaming\n",
    "        )\n",
    "\n",
    "        # Iterate through the response chunks\n",
    "        full_response = \"\"  # Keep track of the full response if needed later\n",
    "\n",
    "        # Loop through each chunk of the response as it arrives\n",
    "        for chunk in stream:\n",
    "            # Check if this chunk contains actual text content\n",
    "            if chunk.choices[0].delta and chunk.choices[0].delta.content:\n",
    "                # Extract the text from this chunk\n",
    "                text_chunk = chunk.choices[0].delta.content\n",
    "                # Add this chunk to our growing response\n",
    "                full_response += text_chunk\n",
    "                # 'yield' - it sends the current state of the response to Gradio\n",
    "                # This makes the text appear to be typing in real-time\n",
    "                yield full_response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during streaming: {e}\")\n",
    "        yield f\"Sorry, I encountered an error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9180c52-f24d-40f7-a4dc-4fe1b5c2ca92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/gradio/interface.py:418: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Streaming Gradio Interface...\n",
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradio interface using the Streaming function\n",
    "# Notice the fn points to the new 'stream_ai_tutor_response' function. The rest is the same!\n",
    "ai_tutor_interface_streaming = gr.Interface(\n",
    "    fn = stream_ai_tutor_response,  # Use the generator function\n",
    "    inputs = gr.Textbox(lines = 2, placeholder = \"Ask the AI Tutor anything...\", label = \"Your Question\"),\n",
    "    outputs = gr.Markdown(\n",
    "        label = \"AI Tutor's Answer (Streaming)\", container = True, height = 250\n",
    "    ),  # Output is still a Markdown (it renders as HTML), container lets it be scrollable and height is set to 250px (for better visibility)\n",
    "    title = \"ðŸ¤– AI Tutor with Streaming\",\n",
    "    description = \"Enter your question. The answer will appear word-by-word!\",\n",
    "    allow_flagging = \"never\",\n",
    ")\n",
    "\n",
    "print(\"Launching Streaming Gradio Interface...\")\n",
    "ai_tutor_interface_streaming.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c3be21-b78e-494f-b327-6632af592a58",
   "metadata": {},
   "source": [
    "## ADD AN EXPLANATION LEVEL SLIDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6be013c4-222c-49b7-a382-50345ed7fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping for explanation levels\n",
    "explanation_levels = {\n",
    "    1: \"like I'm 5 years old\",\n",
    "    2: \"like I'm 10 years old\",\n",
    "    3: \"like a high school student\",\n",
    "    4: \"like a college student\",\n",
    "    5: \"like an expert in the field\",\n",
    "    6: \"like an Einstein PhD-level mad scientist\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "368b9cc2-7319-4e2f-8935-29ef0768be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that accepts question and level and streams the response\n",
    "def stream_ai_tutor_response_with_level(user_question, explanation_level_value):\n",
    "    \"\"\"\n",
    "    Streams AI Tutor response based on user question and selected explanation level.\n",
    "\n",
    "    Args:\n",
    "        user_question (str): The question from the user.\n",
    "        explanation_level_value (int): The value from the slider (1-6).\n",
    "\n",
    "    Yields:\n",
    "        str: Chunks of the AI's response.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the descriptive text for the chosen level\n",
    "    level_description = explanation_levels.get(\n",
    "        explanation_level_value, \"clearly and concisely\"\n",
    "    ) \n",
    "\n",
    "    # Construct the system prompt dynamically based on the level\n",
    "    system_prompt = f\"You are a helpful AI Tutor. Explain the following concept {level_description}.\"\n",
    "\n",
    "    print(f\"DEBUG: Using System Prompt: '{system_prompt}'\")  # For checking\n",
    "\n",
    "    try:\n",
    "        stream = openai_client.chat.completions.create(\n",
    "            model = \"gpt-4o-mini\",\n",
    "            messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_question}],\n",
    "            temperature = 0.7,\n",
    "            stream = True,\n",
    "        )\n",
    "\n",
    "        # Iterate through the response chunks\n",
    "        full_response = \"\"  # Keep track of the full response if needed later\n",
    "\n",
    "        # Loop through each chunk of the response as it arrives\n",
    "        for chunk in stream:\n",
    "            # Check if this chunk contains actual text content\n",
    "            if chunk.choices[0].delta and chunk.choices[0].delta.content:\n",
    "                # Extract the text from this chunk\n",
    "                text_chunk = chunk.choices[0].delta.content\n",
    "                # Add this chunk to our growing response\n",
    "                full_response += text_chunk\n",
    "                # 'yield' - it sends the current state of the response to Gradio\n",
    "                # This makes the text appear to be typing in real-time\n",
    "                yield full_response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during streaming: {e}\")\n",
    "        yield f\"Sorry, I encountered an error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "407a9d88-99ed-4b28-9ca6-306cc22651a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/gradio/interface.py:418: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Advanced Gradio Interface with Slider...\n",
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Gradio interface with both Textbox and slider inputs\n",
    "ai_tutor_interface_slider = gr.Interface(fn = stream_ai_tutor_response_with_level,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines = 3, placeholder = \"Ask the AI Tutor a question...\", label = \"Your Question\"),\n",
    "        gr.Slider(\n",
    "            minimum = 1,\n",
    "            maximum = 6,\n",
    "            step = 1,  # Only allow whole numbers\n",
    "            value = 3,  # Default level (high school)\n",
    "            label = \"Explanation Level\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs = gr.Markdown(label = \"AI Tutor's Explanation (Streaming)\", container = True, height = 250),\n",
    "    title = \"ðŸŽ“ Advanced AI Tutor\",\n",
    "    description = \"Ask a question and select the desired level of explanation using the slider.\",\n",
    "    allow_flagging = \"never\",\n",
    ")\n",
    "\n",
    "print(\"Launching Advanced Gradio Interface with Slider...\")\n",
    "ai_tutor_interface_slider.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
